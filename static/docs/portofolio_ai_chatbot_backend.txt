Portofolio AI Chatbot Backend - Knowledge Document
=================================================

Portofolio AI Chatbot Backend Github Link: https://github.com/fadhilahmadd/portofolio-ai-backend

Overview
--------
This backend application powers a personal portofolio AI chatbot for Fadhil Ahmad Hidayat.
It is designed to answer questions about skills, projects, and experience by using a
Retrieval-Augmented Generation (RAG) approach. The chatbot processes custom knowledge
sources such as resumes, LinkedIn profiles, and other personal documents to provide
accurate and context-aware responses.

Key Features
------------
1. Conversational AI
   - The chatbot engages in natural conversations about skills, projects, and experience.
   - Supports follow-up questions with conversation memory.

2. Streaming Responses
   - Uses Server-Sent Events (SSE) to send responses token-by-token for a dynamic chat experience.

3. Richly Formatted Answers
   - Generates answers with markdown-like formatting for clarity and easy rendering.

4. Retrieval-Augmented Generation (RAG)
   - Pulls relevant information from a custom knowledge base before generating answers.
   - Knowledge base can include PDFs, websites, and other structured documents.

5. Conversation Memory
   - Tracks each user session via a UUID `session_id`.
   - Maintains context for ongoing chats.

6. Hiring Manager Mode
   - Detects recruiter interactions and proactively highlights relevant skills and achievements.

7. Analytics
   - Logs all conversations to a local SQLite database.
   - Includes analytics for understanding user interaction patterns.

8. Suggested Follow-up Questions
   - After each answer, provides relevant follow-up queries to keep the conversation flowing.

9. Fully Asynchronous
   - Built with FastAPI and aiosqlite for high-performance, non-blocking I/O.

10. Cached RAG Pipelines
    - Improves performance by reusing retrieval and generation chains.

11. Automated Testing
    - Includes pytest test suites for quality assurance.

Technology Stack
----------------
- Backend: FastAPI
- LLM Framework: LangChain
- Language Model: Google Gemini (Flash)
- Vector Store: FAISS
- Database: SQLite with SQLAlchemy and aiosqlite
- Testing: pytest, pytest-asyncio
- Key Python Libraries: pydantic, langchain-google-genai, uvicorn, python-dotenv

Testing
-------
- Run `pytest` after installing testing dependencies to verify functionality.

Deployment
----------
- Docker:
  - Build image: `docker build -t portofolio-ai-backend:latest .`
  - Run container with environment variables set.
- Docker Compose:
  - Configure `.env` file.
  - Start with `docker compose up -d --build`.


Customizing the Knowledge Base
------------------------------
- Knowledge sources are defined in `app/core/knowledge_sources.py`.
- Sources can be PDFs in `static/docs/` or web URLs.
- After updating sources, delete `static/faiss_index` to rebuild the vector store.

License
-------
This project is licensed under the MIT License.